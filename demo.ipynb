{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfeae9f-f250-484e-ac68-047a7c53f6d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14437d9-acbc-4d5b-922e-1182847ed199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fvib import calc_K, VIB, FVIB, Deterministic\n",
    "from networks import MnistFeatureExtractor\n",
    "from loss import FVIBLoss, KLLoss, DistortionTaylorApproxLoss\n",
    "from utils import train_FVIB, train_VIB, fvib_ib_curve\n",
    "from calibration import CalibrateFVIB, split_valset, calc_logits, ECELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c2238-59ee-4ec2-a739-4dff7f09ab3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf400387-da73-4611-8d54-4489f692b016",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71cf73-5efd-4d7c-955c-e3a428f5b917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "d = 10 #the number of classes\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e62368b-0261-47ad-a8ac-5223e4fdafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_path, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_path, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c4e043-ca4f-48a9-b0dc-e807b590fac2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a1d8c-9561-4991-9e85-d492bea037fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_path = './results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f943dfd-03c0-47f2-bdad-3dd23ce446cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "lr = 0.0001\n",
    "dim=256 #dimension of z for non-FVIB model (for FVIB, dim = d-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee9a96-3393-49ff-980d-ca1ac1caebca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train FVIB\n",
    "betas = [0.001, 0.1, 0.5] #Beta to record losses during training\n",
    "net = MnistFeatureExtractor(1024, d-1).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.97) # set None if not used\n",
    "path = result_path + \"/fvib\"\n",
    "train_FVIB(n_epochs, d, net, train_loader, test_loader, betas, path, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdafc4-1e25-4574-a1e3-49a39c826d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train VIB\n",
    "betas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.]\n",
    "for beta in betas:\n",
    "    net = MnistFeatureExtractor(1024, 2*dim).to(device)\n",
    "    vib = VIB(2*dim, d, -5, 1)\n",
    "    net_optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    net_scheduler = optim.lr_scheduler.StepLR(net_optimizer, step_size=2, gamma=0.97)\n",
    "    vib_optimizer = optim.Adam(vib.parameters(), lr=lr)\n",
    "    vib_scheduler = optim.lr_scheduler.StepLR(vib_optimizer, step_size=2, gamma=0.97)\n",
    "    path = result_path + f\"/vib/beta_{beta}\"\n",
    "    train_VIB(n_epochs, d, net, vib, train_loader, test_loader, beta, path, net_optimizer, vib_optimizer, net_scheduler, vib_scheduler)\n",
    "    #set use_dta_for_loss = True to train VIB Taylor approx\n",
    "    #set sq_vib = True for sqVIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b297848-6096-4d11-a9c8-123b92a21878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train baseline\n",
    "net = MnistFeatureExtractor(1024, dim).to(device)\n",
    "vib = Deterministic(dim, d).to(device)\n",
    "net_optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "net_scheduler = optim.lr_scheduler.StepLR(net_optimizer, step_size=2, gamma=0.97)\n",
    "vib_optimizer = optim.Adam(vib.parameters(), lr=lr)\n",
    "vib_scheduler = optim.lr_scheduler.StepLR(vib_optimizer, step_size=2, gamma=0.97)\n",
    "path = result_path + \"/base\"\n",
    "train_VIB(n_epochs, d, net, vib, train_loader, test_loader, 0, path, net_optimizer, vib_optimizer, net_scheduler, vib_scheduler,is_deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac759d0-74a4-4b5d-ae8f-c38a0eb144fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot IB Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f9fb2-f89c-470d-8131-cb356d9ff495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_after_ts = 0.997 #value of c in Confidence Tuning, set None if not used\n",
    "betas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "H_Y= np.log(d) #Entropy of Y\n",
    "\n",
    "#load values for VIB\n",
    "vib_train_I_Z_Y = []\n",
    "vib_train_I_X_Z = []\n",
    "vib_test_I_Z_Y = []\n",
    "vib_test_I_X_Z = []\n",
    "for beta in betas:\n",
    "    path = result_path + f'/vib/beta_{beta}'\n",
    "    train_CE = np.load(path+\"/train_ce_loss.npy\")\n",
    "    test_CE = np.load(path+\"/test_ce_loss.npy\")\n",
    "    train_KL = np.load(path+\"/train_kl_loss.npy\")\n",
    "    test_KL = np.load(path+\"/test_kl_loss.npy\")\n",
    "    vib_train_I_Z_Y.append(-train_CE[-1]+H_Y)\n",
    "    vib_train_I_X_Z.append(train_KL[-1])\n",
    "    vib_test_I_Z_Y.append(-test_CE[-1]+H_Y)\n",
    "    vib_test_I_X_Z.append(test_KL[-1])\n",
    "\n",
    "# evaluate FVIB with varying beta\n",
    "path = result_path + '/fvib'\n",
    "net = MnistFeatureExtractor(1024, d-1).to(device)\n",
    "net.load_state_dict(torch.load(path+'/fe_weight.pth'))\n",
    "test_CEs, test_KLs, test_DTAs, test_acc = fvib_ib_curve(betas, path, test_loader, net, 1, conf_after_ts)\n",
    "train_CEs, train_KLs, train_DTAs, train_acc = fvib_ib_curve(betas, path, train_loader, net, 1, conf_after_ts)\n",
    "\n",
    "fvib_train, vib_train, fvib_test, vib_test = (train_KLs, -train_CEs+H_Y), (vib_train_I_X_Z, vib_train_I_Z_Y), (test_KLs, -test_CEs+H_Y), (vib_test_I_X_Z, vib_test_I_Z_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900871e-da08-4086-a8ad-4ad531710f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6,2), tight_layout=True)\n",
    "axes[0].set_title(\"Training\", fontsize=13)\n",
    "axes[0].plot(*vib_train, label=\"VIB\",marker=\"^\",   markersize=5,color=\"C0\")\n",
    "axes[0].plot(*fvib_train, label=\"FVIB\",marker=\".\",   markersize=8,color=\"C1\")\n",
    "axes[1].set_title(\"Test\", fontsize=13)\n",
    "axes[1].plot(*vib_test, label=\"VIB\",marker=\"^\",   markersize=5,color=\"C0\")\n",
    "axes[1].plot(*fvib_test, label=\"FVIB\",marker=\".\",   markersize=8,color=\"C1\")\n",
    "axes[0].set_xlim(0, fvib_train[0][0])\n",
    "axes[1].set_xlim(0, fvib_test[0][0])\n",
    "axes[0].legend(fontsize=12, bbox_to_anchor=(1, 0), loc='lower right', borderaxespad=1)\n",
    "axes[0].set_xlabel(r'$I(X, Z)$')\n",
    "axes[1].set_xlabel(r'$I(X, Z)$')\n",
    "axes[0].set_ylabel(r'$I(Z, Y)$')\n",
    "axes[1].set_ylabel(r'$I(Z, Y)$')\n",
    "fig.savefig(result_path+'/ib_curve.pdf', bbox_inches=\"tight\", pad_inches=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407cdd7d-3667-4f7e-91e6-2d03700aeef1",
   "metadata": {},
   "source": [
    "## Continuous Optimization of Beta for Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ddf465-0cec-4f43-a135-14ad6c856f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split validation set for calibration\n",
    "num_val_data=1000\n",
    "val_loader, test_loader = split_valset(testset, num_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30644f3-28c1-45a5-8a4d-66cf101f541f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define model\n",
    "net = MnistFeatureExtractor(1024, d-1).to(device)\n",
    "net.load_state_dict(torch.load(result_path+'/fvib/fe_weight.pth'))\n",
    "K = torch.load(result_path+'/fvib/K.pt')\n",
    "model = CalibrateFVIB(net, K, num_samples=30, conf_after_ts=0.997, max_iter=50, lr=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa62fbd-a371-4eb7-8368-9dbd2ce6a1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimize beta\n",
    "model.set_beta(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7346bff-889e-45e0-a70f-c94b55b1f846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Validate calibration performance\n",
    "eceloss = ECELoss()\n",
    "logits, labels = calc_logits(model, test_loader)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "acc = (predicted == labels).sum().item()/ len(labels)\n",
    "ece = eceloss(logits, labels, False)[0].item()\n",
    "print(f\"acc:{acc*100}, ece:{ece*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
